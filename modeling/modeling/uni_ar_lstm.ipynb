{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8352deb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 08:04:48.278969: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-06 08:04:48.280100: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-06 08:04:48.289532: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-06 08:04:48.303977: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743941088.324417  358787 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743941088.333008  358787 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743941088.352185  358787 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743941088.352221  358787 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743941088.352264  358787 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743941088.352286  358787 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-06 08:04:48.357801: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras import Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load data (FRED-MD)\n",
    "df = pd.read_csv('../current.csv')\n",
    "\n",
    "# Remove the first row (transformation codes)\n",
    "transformation_codes = df.iloc[0]  # Transformation codes can be applied if needed\n",
    "df = df.iloc[1:]\n",
    "\n",
    "# Set the first column as the index and datetime\n",
    "df.set_index(df.columns[0], inplace=True)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "# Dropna\n",
    "data = df.dropna()\n",
    "\n",
    "# Create train data and target\n",
    "target = (data['CPIAUCSL'].diff(12) / data['CPIAUCSL'].shift(12)) * 100\n",
    "target = target.shift(-12).dropna()\n",
    "data = data.loc[target.index]\n",
    "train = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14903b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 08:08:52.629326: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "/tmp/ipykernel_358787/2541705606.py:88: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_log = pd.concat([df_log, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "horizons = list(range(4, 12*5 + 4, 12))\n",
    "for forecast_horizon in horizons:\n",
    "    series = target.values  # our univariate series (change in CPI)\n",
    "\n",
    "    for context_window in [1, 2, 4, 6, 12, 24]:\n",
    "        for dropout_rate in [0.0, 0.1, 0.2, 0.3]:\n",
    "            # how many training windows we can make before the final test block\n",
    "            cutoff = len(series) - forecast_horizon\n",
    "\n",
    "            # — build X (context_window steps) and y (next step) —\n",
    "            X, y = [], []\n",
    "            for i in range(cutoff - context_window):\n",
    "                X.append(series[i : i + context_window])\n",
    "                y.append(series[i + context_window])\n",
    "            X = np.array(X).reshape(-1, context_window, 1)\n",
    "            y = np.array(y).reshape(-1, 1)\n",
    "\n",
    "            # — scale inputs and outputs separately —\n",
    "            scaler_X = MinMaxScaler()\n",
    "            X_scaled = scaler_X.fit_transform(\n",
    "                X.reshape(-1, 1)\n",
    "            ).reshape(X.shape)\n",
    "\n",
    "            scaler_y = MinMaxScaler()\n",
    "            y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "            # — train / val / test split —\n",
    "            n = X_scaled.shape[0]\n",
    "            test_size = forecast_horizon\n",
    "            val_size = int((n - test_size) * 0.1)\n",
    "\n",
    "            X_train = X_scaled[: n - test_size - val_size]\n",
    "            y_train = y_scaled[: n - test_size - val_size]\n",
    "            X_val   = X_scaled[n - test_size - val_size : n - test_size]\n",
    "            y_val   = y_scaled[n - test_size - val_size : n - test_size]\n",
    "\n",
    "            # — build a one‐step LSTM —\n",
    "            model = Sequential([\n",
    "                Input((context_window, 1)),\n",
    "                LSTM(64, return_sequences=True),\n",
    "                Dropout(dropout_rate),\n",
    "                LSTM(64),\n",
    "                Dropout(dropout_rate),\n",
    "                Dense(1)\n",
    "            ])\n",
    "            model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "            # — fit with early stopping —\n",
    "            es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                shuffle=False,\n",
    "                validation_data=(X_val, y_val),\n",
    "                callbacks=[es],\n",
    "                verbose=0\n",
    "            )\n",
    "\n",
    "            # — iterative, autoregressive forecasting —\n",
    "            history = series[-context_window:].copy()\n",
    "            forecast = []\n",
    "            for _ in range(forecast_horizon):\n",
    "                x_in = scaler_X.transform(history.reshape(-1,1)).reshape(1, context_window, 1)\n",
    "                yhat_s = model.predict(x_in, verbose=0)\n",
    "                yhat   = scaler_y.inverse_transform(yhat_s)[0,0]\n",
    "                forecast.append(yhat)\n",
    "                # roll the window forward\n",
    "                history = np.append(history[1:], yhat)\n",
    "\n",
    "            # — compute metrics on the last `forecast_horizon` true vals —\n",
    "            y_true = series[-forecast_horizon:]\n",
    "            rmse = np.sqrt(mean_squared_error(y_true, forecast))\n",
    "            mae  = mean_absolute_error(y_true, forecast)\n",
    "\n",
    "            # — log to CSV  —\n",
    "            fp = \"uni_ar_lstm.csv\"\n",
    "            df_log = pd.read_csv(fp)\n",
    "            new_row = {\n",
    "                'forecast_horizon': forecast_horizon,\n",
    "                'context_window':   context_window,\n",
    "                'dropout_rate':     dropout_rate,\n",
    "                'rmse':             rmse,\n",
    "                'mae':              mae,\n",
    "                'forecast':         list(forecast),\n",
    "                'true_vals':        list(y_true.tolist())\n",
    "            }\n",
    "            df_log = pd.concat([df_log, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            df_log.to_csv(fp, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3ca30b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
