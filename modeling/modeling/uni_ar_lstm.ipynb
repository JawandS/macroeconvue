{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8352deb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras import Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load data (FRED-MD)\n",
    "df = pd.read_csv('../current.csv')\n",
    "\n",
    "# Remove the first row (transformation codes)\n",
    "transformation_codes = df.iloc[0]  # Transformation codes can be applied if needed\n",
    "df = df.iloc[1:]\n",
    "\n",
    "# Set the first column as the index and datetime\n",
    "df.set_index(df.columns[0], inplace=True)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "# Dropna\n",
    "data = df.dropna()\n",
    "\n",
    "# Create train data and target\n",
    "target = (data['CPIAUCSL'].diff(12) / data['CPIAUCSL'].shift(12)) * 100\n",
    "target = target.shift(-12).dropna()\n",
    "data = data.loc[target.index]\n",
    "train = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "639a8b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set deterministic variables\n",
    "SEED = 42\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Disable GPU for determinism\n",
    "tf.config.experimental.set_visible_devices([], 'GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14903b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3594/2583072218.py:94: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_log = pd.concat([df_log, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "series = target.values  # your univariate series\n",
    "\n",
    "for forecast_horizon in range(4, 12*5 + 4, 12):\n",
    "    for context_window in [1, 2, 4, 6, 12, 24]:\n",
    "        for dropout_rate in [0.0, 0.1, 0.2, 0.3]:\n",
    "            \n",
    "            # Check if there's enough data for this combination\n",
    "            total_required = context_window + forecast_horizon\n",
    "\n",
    "            # Cutoff to ensure test data is not included in training\n",
    "            cutoff = len(series) - forecast_horizon\n",
    "            series_trainval = series[:cutoff]\n",
    "            series_test = series[cutoff:]\n",
    "\n",
    "            # Build training/val data\n",
    "            X, y = [], []\n",
    "            for i in range(len(series_trainval) - context_window):\n",
    "                X.append(series_trainval[i : i + context_window])\n",
    "                y.append(series_trainval[i + context_window])\n",
    "            X = np.array(X).reshape(-1, context_window, 1)\n",
    "            y = np.array(y).reshape(-1, 1)\n",
    "\n",
    "            # Split train/val\n",
    "            n = X.shape[0]\n",
    "            val_size = int(n * 0.1)\n",
    "            X_train = X[: n - val_size]\n",
    "            y_train = y[: n - val_size]\n",
    "            X_val   = X[n - val_size :]\n",
    "            y_val   = y[n - val_size :]\n",
    "\n",
    "            # Fit scalers ONLY on training data\n",
    "            scaler_X = MinMaxScaler()\n",
    "            X_train_scaled = scaler_X.fit_transform(\n",
    "                X_train.reshape(-1, 1)\n",
    "            ).reshape(X_train.shape)\n",
    "            X_val_scaled = scaler_X.transform(\n",
    "                X_val.reshape(-1, 1)\n",
    "            ).reshape(X_val.shape)\n",
    "\n",
    "            scaler_y = MinMaxScaler()\n",
    "            y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "            y_val_scaled = scaler_y.transform(y_val)\n",
    "\n",
    "            # Build model\n",
    "            model = Sequential([\n",
    "                Input((context_window, 1)),\n",
    "                LSTM(64, return_sequences=True),\n",
    "                Dropout(dropout_rate),\n",
    "                LSTM(64),\n",
    "                Dropout(dropout_rate),\n",
    "                Dense(1)\n",
    "            ])\n",
    "            model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "            # Train\n",
    "            es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "            model.fit(\n",
    "                X_train_scaled, y_train_scaled,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                shuffle=False,\n",
    "                validation_data=(X_val_scaled, y_val_scaled),\n",
    "                callbacks=[es],\n",
    "                verbose=0\n",
    "            )\n",
    "\n",
    "            # Prepare input history ending BEFORE test data\n",
    "            history = series[cutoff - context_window : cutoff].copy()\n",
    "            forecast = []\n",
    "            for _ in range(forecast_horizon):\n",
    "                x_in = scaler_X.transform(history.reshape(-1, 1)).reshape(1, context_window, 1)\n",
    "                yhat_s = model.predict(x_in, verbose=0)\n",
    "                yhat = scaler_y.inverse_transform(yhat_s)[0, 0]\n",
    "                forecast.append(yhat)\n",
    "                history = np.append(history[1:], yhat)\n",
    "\n",
    "            # Evaluate\n",
    "            y_true = series_test\n",
    "            rmse = np.sqrt(mean_squared_error(y_true, forecast))\n",
    "            mae = mean_absolute_error(y_true, forecast)\n",
    "\n",
    "            # — log to CSV  —\n",
    "            fp = \"uni_ar_lstm.csv\"\n",
    "            df_log = pd.read_csv(fp)\n",
    "            new_row = {\n",
    "                'forecast_horizon': forecast_horizon,\n",
    "                'context_window':   context_window,\n",
    "                'dropout_rate':     dropout_rate,\n",
    "                'rmse':             rmse,\n",
    "                'mae':              mae,\n",
    "                'forecast':         list(forecast),\n",
    "                'actual':        list(y_true.tolist())\n",
    "            }\n",
    "            df_log = pd.concat([df_log, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            df_log.to_csv(fp, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3ca30b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
