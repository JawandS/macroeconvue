{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (FRED-MD)\n",
    "df = pd.read_csv(\n",
    "    '/home/js/macroeconvue/nowcasting/current.csv',\n",
    "    index_col='sasdate'\n",
    "    )\n",
    "# Drop target variable (CPIAUCSL)\n",
    "target = df['CPIAUCSL']\n",
    "df = df.drop(columns=['CPIAUCSL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the series stationary\n",
    "def transform_series(series, code):\n",
    "    if code == 1:\n",
    "        return series  # No transformation\n",
    "    elif code == 2:\n",
    "        return series.diff().dropna()  # First difference\n",
    "    elif code == 3:\n",
    "        return series.diff().diff().dropna()  # Second difference\n",
    "    elif code == 4:\n",
    "        return np.log(series).dropna()  # Logarithm\n",
    "    elif code == 5:\n",
    "        return np.log(series).diff().dropna()  # First difference of logarithm\n",
    "    elif code == 6:\n",
    "        return np.log(series).diff().diff().dropna()  # Second difference of logarithm\n",
    "    elif code == 7:\n",
    "        return series.pct_change().dropna()  # Percentage change\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown transformation code: {code}\")\n",
    "\n",
    "transformed_data = {}\n",
    "transformation_codes = df.iloc[0]  # Assuming the first row contains the codes\n",
    "data = df.iloc[1:]  # The actual data starts from the second row\n",
    "\n",
    "for column in data.columns:\n",
    "    code = transformation_codes[column]\n",
    "    transformed_data[column] = transform_series(data[column], code)\n",
    "\n",
    "df = pd.DataFrame(transformed_data).dropna(how='all')  # Drop rows with all NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the data\n",
    "df = pd.DataFrame(StandardScaler().fit_transform(df), columns=df.columns, index=df.index)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA fto look for the number of components to retain\n",
    "from sklearn.decomposition import PCA\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# pca = PCA()\n",
    "# pca.fit(df)\n",
    "\n",
    "# cumulative_variance = pca.explained_variance_ratio_.cumsum()\n",
    "\n",
    "# # Plot cumulative explained variance\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(cumulative_variance, marker='o', linestyle='--')\n",
    "# plt.xlabel('Number of Components')\n",
    "# plt.ylabel('Cumulative Explained Variance')\n",
    "# plt.title('Explained Variance by Number of Components')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA len: 390, Original: 390\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>...</th>\n",
       "      <th>PC31</th>\n",
       "      <th>PC32</th>\n",
       "      <th>PC33</th>\n",
       "      <th>PC34</th>\n",
       "      <th>PC35</th>\n",
       "      <th>PC36</th>\n",
       "      <th>PC37</th>\n",
       "      <th>PC38</th>\n",
       "      <th>PC39</th>\n",
       "      <th>PC40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RPI</th>\n",
       "      <td>0.034481</td>\n",
       "      <td>-0.081739</td>\n",
       "      <td>-0.068953</td>\n",
       "      <td>-0.092153</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>-0.273636</td>\n",
       "      <td>-0.289818</td>\n",
       "      <td>0.398063</td>\n",
       "      <td>-0.132497</td>\n",
       "      <td>-0.177616</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071687</td>\n",
       "      <td>-0.005041</td>\n",
       "      <td>-0.003556</td>\n",
       "      <td>-0.051049</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.072719</td>\n",
       "      <td>-0.054323</td>\n",
       "      <td>0.024239</td>\n",
       "      <td>0.049147</td>\n",
       "      <td>-0.039312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W875RX1</th>\n",
       "      <td>0.043448</td>\n",
       "      <td>-0.117144</td>\n",
       "      <td>-0.074420</td>\n",
       "      <td>-0.049564</td>\n",
       "      <td>-0.085013</td>\n",
       "      <td>-0.106425</td>\n",
       "      <td>-0.033869</td>\n",
       "      <td>0.130573</td>\n",
       "      <td>-0.013163</td>\n",
       "      <td>0.036071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309834</td>\n",
       "      <td>-0.047977</td>\n",
       "      <td>0.351154</td>\n",
       "      <td>-0.098933</td>\n",
       "      <td>0.179590</td>\n",
       "      <td>-0.024453</td>\n",
       "      <td>0.067097</td>\n",
       "      <td>-0.105211</td>\n",
       "      <td>-0.143090</td>\n",
       "      <td>-0.060521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DPCERA3M086SBEA</th>\n",
       "      <td>0.122792</td>\n",
       "      <td>-0.063226</td>\n",
       "      <td>-0.098465</td>\n",
       "      <td>0.045354</td>\n",
       "      <td>0.023704</td>\n",
       "      <td>0.010595</td>\n",
       "      <td>-0.070860</td>\n",
       "      <td>0.054086</td>\n",
       "      <td>-0.045489</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099707</td>\n",
       "      <td>-0.034419</td>\n",
       "      <td>-0.024622</td>\n",
       "      <td>-0.045716</td>\n",
       "      <td>-0.109427</td>\n",
       "      <td>0.004947</td>\n",
       "      <td>0.148523</td>\n",
       "      <td>-0.014004</td>\n",
       "      <td>-0.093088</td>\n",
       "      <td>0.080141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMRMTSPLx</th>\n",
       "      <td>0.096000</td>\n",
       "      <td>-0.072448</td>\n",
       "      <td>-0.100212</td>\n",
       "      <td>0.037263</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>-0.036803</td>\n",
       "      <td>-0.002458</td>\n",
       "      <td>0.029059</td>\n",
       "      <td>-0.040573</td>\n",
       "      <td>-0.023109</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081770</td>\n",
       "      <td>-0.010774</td>\n",
       "      <td>-0.014119</td>\n",
       "      <td>-0.009034</td>\n",
       "      <td>-0.097109</td>\n",
       "      <td>0.098720</td>\n",
       "      <td>0.032700</td>\n",
       "      <td>-0.078907</td>\n",
       "      <td>0.003814</td>\n",
       "      <td>0.065193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RETAILx</th>\n",
       "      <td>0.140828</td>\n",
       "      <td>-0.029037</td>\n",
       "      <td>-0.079120</td>\n",
       "      <td>0.006845</td>\n",
       "      <td>0.015920</td>\n",
       "      <td>-0.001387</td>\n",
       "      <td>-0.103307</td>\n",
       "      <td>0.101696</td>\n",
       "      <td>-0.048474</td>\n",
       "      <td>-0.019287</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087943</td>\n",
       "      <td>-0.050115</td>\n",
       "      <td>-0.028114</td>\n",
       "      <td>-0.079790</td>\n",
       "      <td>-0.083041</td>\n",
       "      <td>0.074133</td>\n",
       "      <td>0.169641</td>\n",
       "      <td>-0.062955</td>\n",
       "      <td>-0.105989</td>\n",
       "      <td>0.124353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UMCSENTx</th>\n",
       "      <td>0.031067</td>\n",
       "      <td>-0.006650</td>\n",
       "      <td>-0.044416</td>\n",
       "      <td>0.028852</td>\n",
       "      <td>-0.058411</td>\n",
       "      <td>0.114273</td>\n",
       "      <td>-0.151772</td>\n",
       "      <td>0.091813</td>\n",
       "      <td>0.027816</td>\n",
       "      <td>0.097119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.362074</td>\n",
       "      <td>-0.027771</td>\n",
       "      <td>-0.287264</td>\n",
       "      <td>0.412850</td>\n",
       "      <td>-0.305325</td>\n",
       "      <td>0.155843</td>\n",
       "      <td>-0.113642</td>\n",
       "      <td>0.073663</td>\n",
       "      <td>0.144311</td>\n",
       "      <td>0.235216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTCOLNVHFNM</th>\n",
       "      <td>0.016934</td>\n",
       "      <td>0.005823</td>\n",
       "      <td>-0.016231</td>\n",
       "      <td>0.074108</td>\n",
       "      <td>0.210359</td>\n",
       "      <td>0.232328</td>\n",
       "      <td>0.152782</td>\n",
       "      <td>0.341158</td>\n",
       "      <td>0.016444</td>\n",
       "      <td>-0.081195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063754</td>\n",
       "      <td>-0.017200</td>\n",
       "      <td>0.029651</td>\n",
       "      <td>0.112404</td>\n",
       "      <td>0.019135</td>\n",
       "      <td>-0.217275</td>\n",
       "      <td>0.207222</td>\n",
       "      <td>-0.080242</td>\n",
       "      <td>0.396246</td>\n",
       "      <td>-0.266723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTCTHFNM</th>\n",
       "      <td>0.016773</td>\n",
       "      <td>0.009038</td>\n",
       "      <td>-0.007257</td>\n",
       "      <td>0.021044</td>\n",
       "      <td>0.276215</td>\n",
       "      <td>0.248237</td>\n",
       "      <td>0.246983</td>\n",
       "      <td>0.447468</td>\n",
       "      <td>0.124558</td>\n",
       "      <td>-0.032936</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039265</td>\n",
       "      <td>0.031558</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>-0.064861</td>\n",
       "      <td>0.029045</td>\n",
       "      <td>0.085820</td>\n",
       "      <td>-0.091886</td>\n",
       "      <td>0.086665</td>\n",
       "      <td>-0.098595</td>\n",
       "      <td>0.124691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INVEST</th>\n",
       "      <td>0.011748</td>\n",
       "      <td>0.018594</td>\n",
       "      <td>0.004939</td>\n",
       "      <td>-0.006219</td>\n",
       "      <td>0.003708</td>\n",
       "      <td>-0.179617</td>\n",
       "      <td>0.026435</td>\n",
       "      <td>-0.033200</td>\n",
       "      <td>0.013989</td>\n",
       "      <td>0.133150</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138504</td>\n",
       "      <td>-0.079306</td>\n",
       "      <td>0.125632</td>\n",
       "      <td>-0.197202</td>\n",
       "      <td>-0.239922</td>\n",
       "      <td>-0.208509</td>\n",
       "      <td>0.214371</td>\n",
       "      <td>0.063920</td>\n",
       "      <td>0.002685</td>\n",
       "      <td>-0.044721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIXCLSx</th>\n",
       "      <td>-0.105142</td>\n",
       "      <td>0.066829</td>\n",
       "      <td>-0.010686</td>\n",
       "      <td>0.137264</td>\n",
       "      <td>0.213191</td>\n",
       "      <td>-0.156890</td>\n",
       "      <td>-0.016009</td>\n",
       "      <td>-0.091678</td>\n",
       "      <td>-0.014785</td>\n",
       "      <td>-0.165004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202131</td>\n",
       "      <td>0.004698</td>\n",
       "      <td>-0.072635</td>\n",
       "      <td>-0.328966</td>\n",
       "      <td>-0.023981</td>\n",
       "      <td>0.048349</td>\n",
       "      <td>-0.079471</td>\n",
       "      <td>0.218156</td>\n",
       "      <td>0.279308</td>\n",
       "      <td>0.003030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      PC1       PC2       PC3       PC4       PC5       PC6  \\\n",
       "RPI              0.034481 -0.081739 -0.068953 -0.092153  0.009781 -0.273636   \n",
       "W875RX1          0.043448 -0.117144 -0.074420 -0.049564 -0.085013 -0.106425   \n",
       "DPCERA3M086SBEA  0.122792 -0.063226 -0.098465  0.045354  0.023704  0.010595   \n",
       "CMRMTSPLx        0.096000 -0.072448 -0.100212  0.037263  0.001539 -0.036803   \n",
       "RETAILx          0.140828 -0.029037 -0.079120  0.006845  0.015920 -0.001387   \n",
       "...                   ...       ...       ...       ...       ...       ...   \n",
       "UMCSENTx         0.031067 -0.006650 -0.044416  0.028852 -0.058411  0.114273   \n",
       "DTCOLNVHFNM      0.016934  0.005823 -0.016231  0.074108  0.210359  0.232328   \n",
       "DTCTHFNM         0.016773  0.009038 -0.007257  0.021044  0.276215  0.248237   \n",
       "INVEST           0.011748  0.018594  0.004939 -0.006219  0.003708 -0.179617   \n",
       "VIXCLSx         -0.105142  0.066829 -0.010686  0.137264  0.213191 -0.156890   \n",
       "\n",
       "                      PC7       PC8       PC9      PC10  ...      PC31  \\\n",
       "RPI             -0.289818  0.398063 -0.132497 -0.177616  ... -0.071687   \n",
       "W875RX1         -0.033869  0.130573 -0.013163  0.036071  ...  0.309834   \n",
       "DPCERA3M086SBEA -0.070860  0.054086 -0.045489  0.000375  ... -0.099707   \n",
       "CMRMTSPLx       -0.002458  0.029059 -0.040573 -0.023109  ... -0.081770   \n",
       "RETAILx         -0.103307  0.101696 -0.048474 -0.019287  ... -0.087943   \n",
       "...                   ...       ...       ...       ...  ...       ...   \n",
       "UMCSENTx        -0.151772  0.091813  0.027816  0.097119  ...  0.362074   \n",
       "DTCOLNVHFNM      0.152782  0.341158  0.016444 -0.081195  ...  0.063754   \n",
       "DTCTHFNM         0.246983  0.447468  0.124558 -0.032936  ... -0.039265   \n",
       "INVEST           0.026435 -0.033200  0.013989  0.133150  ... -0.138504   \n",
       "VIXCLSx         -0.016009 -0.091678 -0.014785 -0.165004  ...  0.202131   \n",
       "\n",
       "                     PC32      PC33      PC34      PC35      PC36      PC37  \\\n",
       "RPI             -0.005041 -0.003556 -0.051049  0.008884  0.072719 -0.054323   \n",
       "W875RX1         -0.047977  0.351154 -0.098933  0.179590 -0.024453  0.067097   \n",
       "DPCERA3M086SBEA -0.034419 -0.024622 -0.045716 -0.109427  0.004947  0.148523   \n",
       "CMRMTSPLx       -0.010774 -0.014119 -0.009034 -0.097109  0.098720  0.032700   \n",
       "RETAILx         -0.050115 -0.028114 -0.079790 -0.083041  0.074133  0.169641   \n",
       "...                   ...       ...       ...       ...       ...       ...   \n",
       "UMCSENTx        -0.027771 -0.287264  0.412850 -0.305325  0.155843 -0.113642   \n",
       "DTCOLNVHFNM     -0.017200  0.029651  0.112404  0.019135 -0.217275  0.207222   \n",
       "DTCTHFNM         0.031558  0.001580 -0.064861  0.029045  0.085820 -0.091886   \n",
       "INVEST          -0.079306  0.125632 -0.197202 -0.239922 -0.208509  0.214371   \n",
       "VIXCLSx          0.004698 -0.072635 -0.328966 -0.023981  0.048349 -0.079471   \n",
       "\n",
       "                     PC38      PC39      PC40  \n",
       "RPI              0.024239  0.049147 -0.039312  \n",
       "W875RX1         -0.105211 -0.143090 -0.060521  \n",
       "DPCERA3M086SBEA -0.014004 -0.093088  0.080141  \n",
       "CMRMTSPLx       -0.078907  0.003814  0.065193  \n",
       "RETAILx         -0.062955 -0.105989  0.124353  \n",
       "...                   ...       ...       ...  \n",
       "UMCSENTx         0.073663  0.144311  0.235216  \n",
       "DTCOLNVHFNM     -0.080242  0.396246 -0.266723  \n",
       "DTCTHFNM         0.086665 -0.098595  0.124691  \n",
       "INVEST           0.063920  0.002685 -0.044721  \n",
       "VIXCLSx          0.218156  0.279308  0.003030  \n",
       "\n",
       "[125 rows x 40 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply PCA to keep 90% of variance\n",
    "pca = PCA(n_components=0.90)\n",
    "pca.fit(df)\n",
    "data = pca.transform(df)\n",
    "print(f\"PCA len: {len(data)}, Original: {len(df)}\")\n",
    "\n",
    "# Look at relationship between original features nad cleanred_df\n",
    "loadings = pca.components_\n",
    "loadings_df = pd.DataFrame(loadings.T, index=df.columns, columns=[f'PC{i+1}' for i in range(loadings.shape[0])])\n",
    "display(loadings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 12:52:20.733394: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-21 12:52:20.763201: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-21 12:52:20.955514: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-21 12:52:21.153398: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742575941.318813     821 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742575941.371061     821 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1742575941.754566     821 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742575941.754634     821 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742575941.754636     821 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742575941.754637     821 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-21 12:52:21.801638: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for the LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Convert data into sequences\n",
    "def create_sequences(X, y, time_steps=10):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:i+time_steps])\n",
    "        ys.append(y[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "time_steps = 10  # Choose based on your data\n",
    "X, y = create_sequences(data, target.values, time_steps)\n",
    "\n",
    "# Split into train and test\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dropout\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Build the LSTM model\u001b[39;00m\n\u001b[32m      4\u001b[39m model = Sequential([\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     LSTM(\u001b[32m50\u001b[39m, activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m, return_sequences=\u001b[38;5;28;01mTrue\u001b[39;00m, kernel_regularizer=\u001b[43ml2\u001b[49m(\u001b[32m0.01\u001b[39m), input_shape=(X_train.shape[\u001b[32m1\u001b[39m], X_train.shape[\u001b[32m2\u001b[39m])),\n\u001b[32m      6\u001b[39m     Dropout(\u001b[32m0.2\u001b[39m),\n\u001b[32m      7\u001b[39m     LSTM(\u001b[32m50\u001b[39m, activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m, return_sequences=\u001b[38;5;28;01mFalse\u001b[39;00m, kernel_regularizer=l2(\u001b[32m0.01\u001b[39m)),\n\u001b[32m      8\u001b[39m     Dropout(\u001b[32m0.2\u001b[39m),\n\u001b[32m      9\u001b[39m     Dense(\u001b[32m25\u001b[39m, activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     10\u001b[39m     Dense(\u001b[32m1\u001b[39m)\n\u001b[32m     11\u001b[39m ])\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Compile and train\u001b[39;00m\n\u001b[32m     14\u001b[39m model.compile(optimizer=Adam(learning_rate=\u001b[32m0.001\u001b[39m), loss=\u001b[33m'\u001b[39m\u001b[33mmean_squared_error\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'l2' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(50, activation='relu', return_sequences=True, kernel_regularizer=l2(0.01), input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(50, activation='relu', return_sequences=False, kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.2),\n",
    "    Dense(25, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile and train\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 861.3079092023606\n",
      "Test MSE: 7619.428151310371\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "train_mse = mean_squared_error(y_train, train_predict)\n",
    "test_mse = mean_squared_error(y_test, test_predict)\n",
    "print(f\"Train MSE: {train_mse}\")\n",
    "print(f\"Test MSE: {test_mse}\")\n",
    "# Inverse transform to get actual values\n",
    "# train_predict = target.iloc[:split].values + train_predict.flatten()\n",
    "# test_predict = target.iloc[split:].values + test_predict.flatten()\n",
    "# # Plot the results\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(14, 7)) \n",
    "# plt.plot(target.index[:split], target.iloc[:split], label='Train Actual', color='blue')\n",
    "# plt.plot(target.index[split:], target.iloc[split:], label='Test Actual', color='orange')\n",
    "# plt.plot(target.index[:split], train_predict, label='Train Predicted', color='green')\n",
    "# plt.plot(target.index[split:], test_predict, label='Test Predicted', color='red')\n",
    "# plt.title('LSTM Model Predictions vs Actual')\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('CPIAUCSL')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
