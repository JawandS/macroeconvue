{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (FRED-MD)\n",
    "df = pd.read_csv(\n",
    "    '/home/js/macroeconvue/nowcasting/current.csv',\n",
    "    index_col='sasdate'\n",
    "    )\n",
    "# Drop target variable (CPIAUCSL)\n",
    "target = df['CPIAUCSL'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the series stationary\n",
    "def transform_series(series, code):\n",
    "    if code == 1:\n",
    "        return series  # No transformation\n",
    "    elif code == 2:\n",
    "        return series.diff().dropna()  # First difference\n",
    "    elif code == 3:\n",
    "        return series.diff().diff().dropna()  # Second difference\n",
    "    elif code == 4:\n",
    "        return np.log(series).dropna()  # Logarithm\n",
    "    elif code == 5:\n",
    "        return np.log(series).diff().dropna()  # First difference of logarithm\n",
    "    elif code == 6:\n",
    "        return np.log(series).diff().diff().dropna()  # Second difference of logarithm\n",
    "    elif code == 7:\n",
    "        return series.pct_change().dropna()  # Percentage change\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown transformation code: {code}\")\n",
    "\n",
    "transformed_data = {}\n",
    "transformation_codes = df.iloc[0]  # Assuming the first row contains the codes\n",
    "data = df.iloc[1:]  # The actual data starts from the second row\n",
    "\n",
    "for column in data.columns:\n",
    "    code = transformation_codes[column]\n",
    "    transformed_data[column] = transform_series(data[column], code)\n",
    "\n",
    "df = pd.DataFrame(transformed_data).dropna(how='all')  # Drop rows with all NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalize the data\n",
    "df = (df - df.mean()) / df.std()\n",
    "# Drop rows with NaN values after transformation\n",
    "df = df.dropna()\n",
    "# Get subsample (everything but last year)\n",
    "df = df.iloc[:-12]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA fto look for the number of components to retain\n",
    "from sklearn.decomposition import PCA\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# pca = PCA()\n",
    "# pca.fit(df)\n",
    "\n",
    "# cumulative_variance = pca.explained_variance_ratio_.cumsum()\n",
    "\n",
    "# # Plot cumulative explained variance\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(cumulative_variance, marker='o', linestyle='--')\n",
    "# plt.xlabel('Number of Components')\n",
    "# plt.ylabel('Cumulative Explained Variance')\n",
    "# plt.title('Explained Variance by Number of Components')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA len: 378, Original: 378\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>...</th>\n",
       "      <th>PC30</th>\n",
       "      <th>PC31</th>\n",
       "      <th>PC32</th>\n",
       "      <th>PC33</th>\n",
       "      <th>PC34</th>\n",
       "      <th>PC35</th>\n",
       "      <th>PC36</th>\n",
       "      <th>PC37</th>\n",
       "      <th>PC38</th>\n",
       "      <th>PC39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RPI</th>\n",
       "      <td>0.012627</td>\n",
       "      <td>0.088826</td>\n",
       "      <td>-0.064423</td>\n",
       "      <td>-0.114434</td>\n",
       "      <td>0.043183</td>\n",
       "      <td>-0.268795</td>\n",
       "      <td>-0.309271</td>\n",
       "      <td>0.406801</td>\n",
       "      <td>-0.144272</td>\n",
       "      <td>-0.110089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083199</td>\n",
       "      <td>-0.058561</td>\n",
       "      <td>-0.002593</td>\n",
       "      <td>-0.012743</td>\n",
       "      <td>-0.032287</td>\n",
       "      <td>-0.048993</td>\n",
       "      <td>-0.087040</td>\n",
       "      <td>0.015759</td>\n",
       "      <td>0.060748</td>\n",
       "      <td>-0.013758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W875RX1</th>\n",
       "      <td>0.012698</td>\n",
       "      <td>0.125040</td>\n",
       "      <td>-0.069472</td>\n",
       "      <td>-0.065059</td>\n",
       "      <td>-0.064132</td>\n",
       "      <td>-0.113268</td>\n",
       "      <td>-0.026840</td>\n",
       "      <td>0.133875</td>\n",
       "      <td>0.002898</td>\n",
       "      <td>0.058705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127318</td>\n",
       "      <td>0.273478</td>\n",
       "      <td>-0.098445</td>\n",
       "      <td>-0.362908</td>\n",
       "      <td>-0.072006</td>\n",
       "      <td>-0.057360</td>\n",
       "      <td>0.187569</td>\n",
       "      <td>-0.071045</td>\n",
       "      <td>-0.137735</td>\n",
       "      <td>0.085632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DPCERA3M086SBEA</th>\n",
       "      <td>0.099447</td>\n",
       "      <td>0.095869</td>\n",
       "      <td>-0.099368</td>\n",
       "      <td>0.048483</td>\n",
       "      <td>0.018754</td>\n",
       "      <td>0.005826</td>\n",
       "      <td>-0.073929</td>\n",
       "      <td>0.046479</td>\n",
       "      <td>-0.046922</td>\n",
       "      <td>0.016520</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049994</td>\n",
       "      <td>-0.106202</td>\n",
       "      <td>-0.060999</td>\n",
       "      <td>0.039548</td>\n",
       "      <td>-0.059059</td>\n",
       "      <td>0.082720</td>\n",
       "      <td>-0.006850</td>\n",
       "      <td>-0.105442</td>\n",
       "      <td>-0.120503</td>\n",
       "      <td>-0.058497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMRMTSPLx</th>\n",
       "      <td>0.072797</td>\n",
       "      <td>0.097884</td>\n",
       "      <td>-0.099025</td>\n",
       "      <td>0.030969</td>\n",
       "      <td>0.007682</td>\n",
       "      <td>-0.040521</td>\n",
       "      <td>-0.003400</td>\n",
       "      <td>0.031026</td>\n",
       "      <td>-0.041557</td>\n",
       "      <td>-0.012060</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036794</td>\n",
       "      <td>-0.078211</td>\n",
       "      <td>-0.020531</td>\n",
       "      <td>0.015241</td>\n",
       "      <td>0.008228</td>\n",
       "      <td>0.036622</td>\n",
       "      <td>-0.091646</td>\n",
       "      <td>-0.128966</td>\n",
       "      <td>-0.013479</td>\n",
       "      <td>0.017506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RETAILx</th>\n",
       "      <td>0.124735</td>\n",
       "      <td>0.067249</td>\n",
       "      <td>-0.082064</td>\n",
       "      <td>0.007449</td>\n",
       "      <td>0.014891</td>\n",
       "      <td>-0.000961</td>\n",
       "      <td>-0.115412</td>\n",
       "      <td>0.089246</td>\n",
       "      <td>-0.051885</td>\n",
       "      <td>-0.001547</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103753</td>\n",
       "      <td>-0.095476</td>\n",
       "      <td>-0.067517</td>\n",
       "      <td>0.030923</td>\n",
       "      <td>-0.096621</td>\n",
       "      <td>0.034195</td>\n",
       "      <td>-0.035685</td>\n",
       "      <td>-0.174957</td>\n",
       "      <td>-0.136561</td>\n",
       "      <td>-0.048969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UMCSENTx</th>\n",
       "      <td>0.024300</td>\n",
       "      <td>0.016735</td>\n",
       "      <td>-0.048159</td>\n",
       "      <td>0.037107</td>\n",
       "      <td>-0.078552</td>\n",
       "      <td>0.098853</td>\n",
       "      <td>-0.157247</td>\n",
       "      <td>0.063427</td>\n",
       "      <td>0.034978</td>\n",
       "      <td>0.100359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011880</td>\n",
       "      <td>0.321511</td>\n",
       "      <td>0.002838</td>\n",
       "      <td>0.393946</td>\n",
       "      <td>0.423744</td>\n",
       "      <td>0.048407</td>\n",
       "      <td>-0.241205</td>\n",
       "      <td>0.035267</td>\n",
       "      <td>0.097881</td>\n",
       "      <td>-0.043795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTCOLNVHFNM</th>\n",
       "      <td>0.016784</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>-0.017665</td>\n",
       "      <td>0.101138</td>\n",
       "      <td>0.187414</td>\n",
       "      <td>0.269285</td>\n",
       "      <td>0.104807</td>\n",
       "      <td>0.348211</td>\n",
       "      <td>0.013876</td>\n",
       "      <td>-0.046519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.148101</td>\n",
       "      <td>0.071346</td>\n",
       "      <td>-0.014960</td>\n",
       "      <td>0.034650</td>\n",
       "      <td>0.069497</td>\n",
       "      <td>0.102337</td>\n",
       "      <td>0.312145</td>\n",
       "      <td>-0.086091</td>\n",
       "      <td>0.360835</td>\n",
       "      <td>-0.168801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTCTHFNM</th>\n",
       "      <td>0.018820</td>\n",
       "      <td>-0.004483</td>\n",
       "      <td>-0.008027</td>\n",
       "      <td>0.047322</td>\n",
       "      <td>0.262802</td>\n",
       "      <td>0.312254</td>\n",
       "      <td>0.180416</td>\n",
       "      <td>0.448072</td>\n",
       "      <td>0.134205</td>\n",
       "      <td>-0.008469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075045</td>\n",
       "      <td>-0.028386</td>\n",
       "      <td>0.032730</td>\n",
       "      <td>-0.036002</td>\n",
       "      <td>-0.053509</td>\n",
       "      <td>-0.062759</td>\n",
       "      <td>-0.128561</td>\n",
       "      <td>0.084642</td>\n",
       "      <td>-0.091913</td>\n",
       "      <td>0.025542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INVEST</th>\n",
       "      <td>0.016303</td>\n",
       "      <td>-0.015234</td>\n",
       "      <td>0.004236</td>\n",
       "      <td>-0.024050</td>\n",
       "      <td>0.034324</td>\n",
       "      <td>-0.178973</td>\n",
       "      <td>0.035653</td>\n",
       "      <td>-0.040940</td>\n",
       "      <td>0.048541</td>\n",
       "      <td>0.112709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221485</td>\n",
       "      <td>-0.132140</td>\n",
       "      <td>-0.137724</td>\n",
       "      <td>-0.076187</td>\n",
       "      <td>-0.125725</td>\n",
       "      <td>0.334812</td>\n",
       "      <td>0.052262</td>\n",
       "      <td>-0.065640</td>\n",
       "      <td>-0.057748</td>\n",
       "      <td>-0.212263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIXCLSx</th>\n",
       "      <td>-0.083479</td>\n",
       "      <td>-0.093167</td>\n",
       "      <td>-0.012578</td>\n",
       "      <td>0.151337</td>\n",
       "      <td>0.212858</td>\n",
       "      <td>-0.151747</td>\n",
       "      <td>0.002685</td>\n",
       "      <td>-0.063883</td>\n",
       "      <td>-0.042992</td>\n",
       "      <td>-0.164865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082497</td>\n",
       "      <td>0.224239</td>\n",
       "      <td>0.031618</td>\n",
       "      <td>0.016941</td>\n",
       "      <td>-0.312575</td>\n",
       "      <td>0.087551</td>\n",
       "      <td>-0.218355</td>\n",
       "      <td>0.117171</td>\n",
       "      <td>0.273531</td>\n",
       "      <td>-0.127822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      PC1       PC2       PC3       PC4       PC5       PC6  \\\n",
       "RPI              0.012627  0.088826 -0.064423 -0.114434  0.043183 -0.268795   \n",
       "W875RX1          0.012698  0.125040 -0.069472 -0.065059 -0.064132 -0.113268   \n",
       "DPCERA3M086SBEA  0.099447  0.095869 -0.099368  0.048483  0.018754  0.005826   \n",
       "CMRMTSPLx        0.072797  0.097884 -0.099025  0.030969  0.007682 -0.040521   \n",
       "RETAILx          0.124735  0.067249 -0.082064  0.007449  0.014891 -0.000961   \n",
       "...                   ...       ...       ...       ...       ...       ...   \n",
       "UMCSENTx         0.024300  0.016735 -0.048159  0.037107 -0.078552  0.098853   \n",
       "DTCOLNVHFNM      0.016784 -0.000143 -0.017665  0.101138  0.187414  0.269285   \n",
       "DTCTHFNM         0.018820 -0.004483 -0.008027  0.047322  0.262802  0.312254   \n",
       "INVEST           0.016303 -0.015234  0.004236 -0.024050  0.034324 -0.178973   \n",
       "VIXCLSx         -0.083479 -0.093167 -0.012578  0.151337  0.212858 -0.151747   \n",
       "\n",
       "                      PC7       PC8       PC9      PC10  ...      PC30  \\\n",
       "RPI             -0.309271  0.406801 -0.144272 -0.110089  ...  0.083199   \n",
       "W875RX1         -0.026840  0.133875  0.002898  0.058705  ...  0.127318   \n",
       "DPCERA3M086SBEA -0.073929  0.046479 -0.046922  0.016520  ... -0.049994   \n",
       "CMRMTSPLx       -0.003400  0.031026 -0.041557 -0.012060  ... -0.036794   \n",
       "RETAILx         -0.115412  0.089246 -0.051885 -0.001547  ... -0.103753   \n",
       "...                   ...       ...       ...       ...  ...       ...   \n",
       "UMCSENTx        -0.157247  0.063427  0.034978  0.100359  ...  0.011880   \n",
       "DTCOLNVHFNM      0.104807  0.348211  0.013876 -0.046519  ... -0.148101   \n",
       "DTCTHFNM         0.180416  0.448072  0.134205 -0.008469  ...  0.075045   \n",
       "INVEST           0.035653 -0.040940  0.048541  0.112709  ...  0.221485   \n",
       "VIXCLSx          0.002685 -0.063883 -0.042992 -0.164865  ...  0.082497   \n",
       "\n",
       "                     PC31      PC32      PC33      PC34      PC35      PC36  \\\n",
       "RPI             -0.058561 -0.002593 -0.012743 -0.032287 -0.048993 -0.087040   \n",
       "W875RX1          0.273478 -0.098445 -0.362908 -0.072006 -0.057360  0.187569   \n",
       "DPCERA3M086SBEA -0.106202 -0.060999  0.039548 -0.059059  0.082720 -0.006850   \n",
       "CMRMTSPLx       -0.078211 -0.020531  0.015241  0.008228  0.036622 -0.091646   \n",
       "RETAILx         -0.095476 -0.067517  0.030923 -0.096621  0.034195 -0.035685   \n",
       "...                   ...       ...       ...       ...       ...       ...   \n",
       "UMCSENTx         0.321511  0.002838  0.393946  0.423744  0.048407 -0.241205   \n",
       "DTCOLNVHFNM      0.071346 -0.014960  0.034650  0.069497  0.102337  0.312145   \n",
       "DTCTHFNM        -0.028386  0.032730 -0.036002 -0.053509 -0.062759 -0.128561   \n",
       "INVEST          -0.132140 -0.137724 -0.076187 -0.125725  0.334812  0.052262   \n",
       "VIXCLSx          0.224239  0.031618  0.016941 -0.312575  0.087551 -0.218355   \n",
       "\n",
       "                     PC37      PC38      PC39  \n",
       "RPI              0.015759  0.060748 -0.013758  \n",
       "W875RX1         -0.071045 -0.137735  0.085632  \n",
       "DPCERA3M086SBEA -0.105442 -0.120503 -0.058497  \n",
       "CMRMTSPLx       -0.128966 -0.013479  0.017506  \n",
       "RETAILx         -0.174957 -0.136561 -0.048969  \n",
       "...                   ...       ...       ...  \n",
       "UMCSENTx         0.035267  0.097881 -0.043795  \n",
       "DTCOLNVHFNM     -0.086091  0.360835 -0.168801  \n",
       "DTCTHFNM         0.084642 -0.091913  0.025542  \n",
       "INVEST          -0.065640 -0.057748 -0.212263  \n",
       "VIXCLSx          0.117171  0.273531 -0.127822  \n",
       "\n",
       "[126 rows x 39 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply PCA to keep 90% of variance\n",
    "pca = PCA(n_components=0.90)\n",
    "pca.fit(df)\n",
    "data = pca.transform(df)\n",
    "print(f\"PCA len: {len(data)}, Original: {len(df)}\")\n",
    "\n",
    "# Look at relationship between original features nad cleanred_df\n",
    "loadings = pca.components_\n",
    "loadings_df = pd.DataFrame(loadings.T, index=df.columns, columns=[f'PC{i+1}' for i in range(loadings.shape[0])])\n",
    "display(loadings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for the LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Convert data into sequences\n",
    "def create_sequences(X, y, time_steps=10):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:i+time_steps])\n",
    "        ys.append(y[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "time_steps = 12  # Choose based on your data\n",
    "X, y = create_sequences(data, target.values, time_steps)\n",
    "\n",
    "# # Split into train and test\n",
    "split = int(0.8 * len(X))\n",
    "split = len(data) - 12  # Use the last 12 months for testing\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 14:34:43.076959: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "/home/js/macroeconvue/nowcasting/.venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 4910.3560\n",
      "Epoch 2/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3176.6904\n",
      "Epoch 3/50\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1324.5220"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 14:34:45.520869: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/home/js/macroeconvue/nowcasting/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n",
      "2025-03-23 14:34:45.682266: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1168.2935\n",
      "Epoch 4/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 846.7857\n",
      "Epoch 5/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 506.4486\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 14:34:45.995630: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 404.2965\n",
      "Epoch 7/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 309.5131\n",
      "Epoch 8/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 235.3949\n",
      "Epoch 9/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 168.3443\n",
      "Epoch 10/50\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 136.5215"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 14:34:46.731224: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 148.6937\n",
      "Epoch 11/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 173.8573\n",
      "Epoch 12/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 129.8931\n",
      "Epoch 13/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 139.4882\n",
      "Epoch 14/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 96.1926\n",
      "Epoch 15/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 126.1105\n",
      "Epoch 16/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 120.4164\n",
      "Epoch 17/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 99.6067\n",
      "Epoch 18/50\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 116.2284"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 14:34:48.048355: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-0s\u001b[0m -31438us/step - loss: 119.4588\n",
      "Epoch 19/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 97.7933\n",
      "Epoch 20/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 77.9023\n",
      "Epoch 21/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 80.7318\n",
      "Epoch 22/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 76.9491\n",
      "Epoch 23/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 90.7536\n",
      "Epoch 24/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 63.7607\n",
      "Epoch 25/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 105.3456\n",
      "Epoch 26/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 87.6969\n",
      "Epoch 27/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 78.1304\n",
      "Epoch 28/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 81.7624\n",
      "Epoch 29/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 80.8737\n",
      "Epoch 30/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 58.8383\n",
      "Epoch 31/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 69.2905\n",
      "Epoch 32/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 60.0784\n",
      "Epoch 33/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 77.7170\n",
      "Epoch 34/50\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 142.5743"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 14:34:50.487800: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 72.0758\n",
      "Epoch 35/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 77.1307\n",
      "Epoch 36/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 48.6789\n",
      "Epoch 37/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 65.2697\n",
      "Epoch 38/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 45.8206\n",
      "Epoch 39/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 59.0567\n",
      "Epoch 40/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 43.9637\n",
      "Epoch 41/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 45.2865\n",
      "Epoch 42/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 56.8996\n",
      "Epoch 43/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 41.9318\n",
      "Epoch 44/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 69.3083\n",
      "Epoch 45/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 62.4981\n",
      "Epoch 46/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 58.8608\n",
      "Epoch 47/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 44.7835\n",
      "Epoch 48/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 780ms/step - loss: 45.9406\n",
      "Epoch 49/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 60.4051\n",
      "Epoch 50/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 47.2197\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[32m     19\u001b[39m train_predict = model.predict(X_train)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m test_predict = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/macroeconvue/nowcasting/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/macroeconvue/nowcasting/.venv/lib/python3.12/site-packages/keras/src/utils/progbar.py:119\u001b[39m, in \u001b[36mProgbar.update\u001b[39m\u001b[34m(self, current, values, finalize)\u001b[39m\n\u001b[32m    116\u001b[39m     message += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     numdigits = \u001b[38;5;28mint\u001b[39m(\u001b[43mmath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog10\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m) + \u001b[32m1\u001b[39m\n\u001b[32m    120\u001b[39m     bar = (\u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(numdigits) + \u001b[33m\"\u001b[39m\u001b[33md/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m\"\u001b[39m) % (current, \u001b[38;5;28mself\u001b[39m.target)\n\u001b[32m    121\u001b[39m     bar = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\x1b\u001b[39;00m\u001b[33m[1m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbar\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\x1b\u001b[39;00m\u001b[33m[0m \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: math domain error"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(50, activation='relu', return_sequences=True, kernel_regularizer=l2(0.01), input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(50, activation='relu', return_sequences=False, kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.2),\n",
    "    Dense(25, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile and train\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 67.09467274807682\n",
      "Test MSE: 4706.87229854542\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "train_mse = mean_squared_error(y_train, train_predict)\n",
    "test_mse = mean_squared_error(y_test, test_predict)\n",
    "print(f\"Train MSE: {train_mse}\")\n",
    "print(f\"Test MSE: {test_mse}\")\n",
    "# Inverse transform to get actual values\n",
    "# train_predict = target.iloc[:split].values + train_predict.flatten()\n",
    "# test_predict = target.iloc[split:].values + test_predict.flatten()\n",
    "# # Plot the results\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(14, 7)) \n",
    "# plt.plot(target.index[:split], target.iloc[:split], label='Train Actual', color='blue')\n",
    "# plt.plot(target.index[split:], target.iloc[split:], label='Test Actual', color='orange')\n",
    "# plt.plot(target.index[:split], train_predict, label='Train Predicted', color='green')\n",
    "# plt.plot(target.index[split:], test_predict, label='Test Predicted', color='red')\n",
    "# plt.title('LSTM Model Predictions vs Actual')\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('CPIAUCSL')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get RMSE for the test set\n",
    "from sklearn.metrics import mean_squared_error\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, test_predict))\n",
    "print(f\"Test RMSE: {test_rmse}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
